{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--dataset DATASET]\n",
      "                             [--savingroot SAVINGROOT] [--dataroot DATAROOT]\n",
      "                             [--manual_seed MANUAL_SEED] [--p1 P1] [--p2 P2]\n",
      "                             [--image_size IMAGE_SIZE]\n",
      "                             [--batch_size BATCH_SIZE]\n",
      "                             [--num_workers NUM_WORKERS]\n",
      "                             [--num_epoches NUM_EPOCHES] [--nc NC] [--nz NZ]\n",
      "                             [--ndf NDF] [--ngf NGF]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /run/user/1435621388/jupyter/kernel-98d6dda4-9fcb-4150-9348-32405e60e1e2.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.utils as utils\n",
    "import torch.nn.functional as F\n",
    "from models import G_CIFAR10,G_MNIST,D_CIFAR10,D_MNIST\n",
    "from tensorboard_logger import configure, log_value\n",
    "\n",
    "from data import generate_c_data, CIFAR10_Complementary\n",
    "\n",
    "from train_test import train,train_data_g,test,test_acc\n",
    "\n",
    "\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.enbaled = True\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def args():\n",
    "    FLAG = argparse.ArgumentParser(description='ACGAN Implement With Pytorch.')\n",
    "    FLAG.add_argument('--dataset', default='MNIST', help='CIFAR10 | MNIST')\n",
    "    FLAG.add_argument('--savingroot', default='../result', help='path to saving.')\n",
    "    FLAG.add_argument('--dataroot', default='data', help='path to dataset.')\n",
    "    FLAG.add_argument('--manual_seed', default=42, help='manual seed.')\n",
    "    FLAG.add_argument('--p1', default= 0.0, type=float, help='p1')\n",
    "    FLAG.add_argument('--p2', default=1.0, type=float, help='p2')\n",
    "    FLAG.add_argument('--image_size', default=32, help='image size.')\n",
    "    FLAG.add_argument('--batch_size', default=128, help='batch size.')\n",
    "    FLAG.add_argument('--num_workers', default=2, help='num workers.')\n",
    "    FLAG.add_argument('--num_epoches', default=20, help='num workers.')\n",
    "    FLAG.add_argument('--nc', default=1, help='channel of input image.')\n",
    "    FLAG.add_argument('--nz', default=64, help='length of noize.')\n",
    "    FLAG.add_argument('--ndf', default=64, help='number of filters.')\n",
    "    FLAG.add_argument('--ngf', default=64, help='number of filters.')\n",
    "    arguments = FLAG.parse_args()\n",
    "    return arguments\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "assert torch.cuda.is_available(), '[!] CUDA required!'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def embed_z(opt):\n",
    "    fixed = Variable(torch.Tensor(100, opt.nz).normal_(0, 1)).cuda()\n",
    "    return fixed\n",
    "\n",
    "\n",
    "\n",
    "def train_gan(opt):\n",
    "\n",
    "    os.makedirs(os.path.join(opt.savingroot,opt.dataset,str(opt.p1 * 100) + '%complementary/' + str(opt.p1) + '_images'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(opt.savingroot,opt.dataset,str(opt.p1 * 100) + '%complementary/' + str(opt.p1) +  '_chkpts'), exist_ok=True)\n",
    "    if not os.path.exists(os.path.join(opt.savingroot,opt.data_r,'data','processed/training'+str(opt.p1)+str(opt.p2)+'.pt')):\n",
    "        generate_c_data(opt)\n",
    "    else:\n",
    "        print('data exits')\n",
    "\n",
    "    #Build networ\n",
    "    if opt.data_r == 'MNIST':\n",
    "        netd = D_MNIST(opt.ndf, opt.nc, num_classes=10).cuda()\n",
    "        netg = G_MNIST( opt.nz, opt.ngf, opt.nc).cuda()\n",
    "    elif opt.data_r == 'CIFAR10':\n",
    "        netd = D_CIFAR10(opt.ndf, opt.nc, num_classes=10).cuda()\n",
    "        netg = G_CIFAR10(opt.nz, opt.ngf, opt.nc).cuda()\n",
    "\n",
    "\n",
    "\n",
    "    optd = optim.Adam(netd.parameters(), lr=0.0002,\n",
    "                      betas=(0.5, 0.999))  # optim.SGD(netd.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)#\n",
    "    optg = optim.Adam(netg.parameters(), lr=0.0002,\n",
    "                      betas=(0.5, 0.999))  # optim.SGD(netg.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)#\n",
    "\n",
    "    print('training_start')\n",
    "    step = 0\n",
    "    acc = []\n",
    "\n",
    "    # configure(os.path.join(opt.savingroot,opt.dataset,str(opt.p1 * 100) + '%complementary/' +  str(opt.p1) + '/logs'), flush_secs=5)\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        CIFAR10_Complementary(os.path.join(opt.savingroot,opt.data_r,'data'), train=False, transform=transforms.Compose([\n",
    "            transforms.Resize(opt.image_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "        ])), batch_size=128, num_workers=2)\n",
    "\n",
    "    fixed = embed_z(opt)\n",
    "\n",
    "    for epoch in range(opt.num_epoches):\n",
    "        print(f'Epoch {epoch:03d}.')\n",
    "        dataset = CIFAR10_Complementary(os.path.join(opt.savingroot,opt.data_r,'data'), transform=tsfm, p1=opt.p1,p2=opt.p2)\n",
    "        # dataset = dset.CIFAR10(root=opt.dataroot, download=True, transform=tsfm)\n",
    "        loader = torch.utils.data.DataLoader(dataset, batch_size=opt.batch_size, shuffle=True, num_workers=2\n",
    "                                             )\n",
    "        # if epoch % 40 == 0 and epoch != 0:\n",
    "        #     for param_group in optd.param_groups:\n",
    "        #         param_group['lr'] = param_group['lr'] / 10\n",
    "        #         print(param_group['lr'])\n",
    "        step = train(netd,netg,optd,optg,loader,epoch,step,opt)\n",
    "\n",
    "        test(netg, fixed, epoch, opt)\n",
    "        acc.append(test_acc(netd, test_loader))\n",
    "\n",
    "    f = open(os.path.join(opt.savingroot,opt.dataset,str(opt.p1 * 100) + '%complementary/'  + 'acc.txt'), 'a')\n",
    "    for cont in acc:\n",
    "        f.writelines(str(cont) + '\\n')\n",
    "\n",
    "    f.close()\n",
    "\n",
    "def train_f_data(opt):\n",
    "    os.makedirs(os.path.join(opt.savingroot, opt.dataset, str(opt.p1 * 100) + '%complementary/' + str(opt.p1) + '_chkpts_fake_data'),exist_ok=True)\n",
    "\n",
    "\n",
    "    if opt.data_r == 'MNIST':\n",
    "        netd = D_MNIST(opt.ndf, opt.nc, num_classes=10).cuda()\n",
    "        netg = G_MNIST( opt.nz, opt.ngf, opt.nc).cuda()\n",
    "    elif opt.data_r == 'CIFAR10':\n",
    "        netd = D_CIFAR10(opt.ndf, opt.nc, num_classes=10).cuda()\n",
    "        netg = G_CIFAR10(opt.nz, opt.ngf, opt.nc).cuda()\n",
    "    print(os.path.join(opt.savingroot, opt.dataset, str(opt.p1 * 100) + '%complementary/' + str(\n",
    "            opt.p1) + f'_chkpts/g_{(opt.num_epoches-1):03d}.pth'))\n",
    "    netg.load_state_dict(torch.load(os.path.join(opt.savingroot, opt.dataset, str(opt.p1 * 100) + '%complementary/' + str(\n",
    "            opt.p1) + f'_chkpts/g_{(opt.num_epoches-1):03d}.pth')))\n",
    "    netg.eval()\n",
    "\n",
    "\n",
    "\n",
    "    # netd = MobileNetV2().cuda()\n",
    "    # netd = VGG('VGG19').cuda()\n",
    "    # netd = ResNet18().cuda()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # netg.load_state_dict(model.state_dict())\n",
    "\n",
    "    optd = optim.Adam(netd.parameters(), lr=0.0002,\n",
    "                      betas=(0.5, 0.999))  # optim.SGD(netd.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)#\n",
    "\n",
    "    print('training_start')\n",
    "    step = 0\n",
    "    acc = []\n",
    "\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        CIFAR10_Complementary(os.path.join(opt.savingroot,opt.data_r,'data'), train=False, transform=transforms.Compose([\n",
    "            transforms.Resize(opt.image_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "        ])), batch_size=128, num_workers=2)\n",
    "\n",
    "    fixed = embed_z(opt)\n",
    "\n",
    "    for epoch in range(opt.num_epoches*2):\n",
    "        print(f'Epoch {epoch:03d}.')\n",
    "        # if epoch % 40 == 0 and epoch != 0:\n",
    "        #     for param_group in optd.param_groups:\n",
    "        #         param_group['lr'] = param_group['lr'] / 10\n",
    "        #         print(param_group['lr'])\n",
    "        step = train_data_g(netd,netg,optd,epoch,step,opt)\n",
    "\n",
    "        test(netg, fixed, epoch, opt)\n",
    "        acc.append(test_acc(netd, test_loader))\n",
    "\n",
    "    f = open(os.path.join(opt.savingroot,opt.dataset,str(opt.p1 * 100) + '%complementary/' + 'acc_f_train.txt'), 'a')\n",
    "    for cont in acc:\n",
    "        f.writelines(str(cont) + '\\n')\n",
    "\n",
    "    f.close()\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    opt = args()\n",
    "    opt.data_r = opt.dataset\n",
    "\n",
    "\n",
    "\n",
    "    if opt.data_r == 'MNIST':\n",
    "        tsfm = transforms.Compose([\n",
    "            transforms.Resize(opt.image_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "        ])\n",
    "    else:\n",
    "        tsfm = transforms.Compose([\n",
    "            transforms.Resize(opt.image_size),\n",
    "            transforms.RandomCrop(opt.image_size, padding=4),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "        ])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    torch.cuda.manual_seed(opt.manual_seed)\n",
    "    opt.dataset = os.path.join(opt.dataset, opt.dataset + '_' + str(opt.p2))\n",
    "\n",
    "    configure(os.path.join(opt.savingroot, opt.dataset, str(opt.p1 * 100) + '%complementary/' + str(opt.p1) + '/logs'),\n",
    "              flush_secs=5)\n",
    "\n",
    "    train_gan(opt)\n",
    "    train_f_data(opt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class G_MNIST(nn.Module):\n",
    "\n",
    "    def __init__(self, nz, ngf, nc):\n",
    "        super(G_MNIST, self).__init__()\n",
    "\n",
    "        self.embed = nn.Embedding(10, nz)\n",
    "\n",
    "        self.conv1 = nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0)\n",
    "        self.bn1 = nn.BatchNorm2d(ngf * 8)\n",
    "\n",
    "        self.conv2 = nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1)\n",
    "        self.bn2 = nn.BatchNorm2d(ngf * 4)\n",
    "\n",
    "        self.conv3 = nn.ConvTranspose2d(ngf * 4, ngf * 1, 4, 2, 1)\n",
    "        self.bn3 = nn.BatchNorm2d(ngf * 1)\n",
    "\n",
    "\n",
    "        self.conv5 = nn.ConvTranspose2d(ngf * 1, nc, 4, 2, 1)\n",
    "\n",
    "        self.relu = nn.ReLU(True)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "        self.__initialize_weights()\n",
    "\n",
    "    def forward(self, z,label):\n",
    "        input = z.mul_(self.embed(label))\n",
    "        x = input.view(input.size(0), -1, 1, 1)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "\n",
    "        x = self.conv5(x)\n",
    "        output = self.tanh(x)\n",
    "        return output\n",
    "\n",
    "    def __initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                m.weight.data.normal_(0.0, 0.02)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.normal_(1.0, 0.02)\n",
    "                m.bias.data.fill_(0)\n",
    "\n",
    "\n",
    "class D_MNIST(nn.Module):\n",
    "\n",
    "    def __init__(self, ndf, nc, num_classes=10):\n",
    "        super(D_MNIST, self).__init__()\n",
    "        self.ndf = ndf\n",
    "        self.lrelu = nn.ReLU()\n",
    "        self.conv1 = nn.Conv2d(nc, ndf, 4, 2, 1)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(ndf , ndf * 4, 4, 2, 1)\n",
    "        self.bn3 = nn.BatchNorm2d(ndf * 4)\n",
    "        self.conv4 = nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1)\n",
    "        self.bn4 = nn.BatchNorm2d(ndf * 8)\n",
    "        self.conv5 = nn.Conv2d(ndf * 8, ndf * 1, 4, 1, 0)\n",
    "        self.gan_linear = nn.Linear(ndf * 1, 1)\n",
    "        self.aux_linear = nn.Linear(ndf * 1, num_classes)\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.__initialize_weights()\n",
    "\n",
    "    def forward(self, input):\n",
    "\n",
    "        x = self.conv1(input)\n",
    "        x = self.lrelu(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.lrelu(x)\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.lrelu(x)\n",
    "\n",
    "        x = self.conv5(x)\n",
    "        x = x.view(-1, self.ndf * 1)\n",
    "        c = self.aux_linear(x)\n",
    "\n",
    "        s = self.gan_linear(x)\n",
    "        s = self.sigmoid(s)\n",
    "        return s.squeeze(1), c.squeeze(1)\n",
    "\n",
    "    def __initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                m.weight.data.normal_(0.0, 0.02)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.normal_(1.0, 0.02)\n",
    "                m.bias.data.fill_(0)\n",
    "\n",
    "class G_CIFAR10(nn.Module):\n",
    "\n",
    "    def __init__(self, nz, ngf, nc):\n",
    "        super(G_CIFAR10, self).__init__()\n",
    "        self.embed = nn.Embedding(10, nz)\n",
    "        self.conv1 = nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0)\n",
    "        self.bn1 = nn.BatchNorm2d(ngf * 8)\n",
    "\n",
    "        self.conv2 = nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1)\n",
    "        self.bn2 = nn.BatchNorm2d(ngf * 4)\n",
    "\n",
    "        self.conv3 = nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1)\n",
    "        self.bn3 = nn.BatchNorm2d(ngf * 2)\n",
    "\n",
    "        self.conv4 = nn.ConvTranspose2d(ngf * 2, ngf * 1, 4, 2, 1)\n",
    "        self.bn4 = nn.BatchNorm2d(ngf * 1)\n",
    "\n",
    "        self.conv5 = nn.ConvTranspose2d(ngf, ngf * 1, 3, 1, 1)\n",
    "        self.bn5 = nn.BatchNorm2d(ngf * 1)\n",
    "\n",
    "        self.conv6 = nn.Conv2d(ngf * 1, nc, 3, 1, 1)\n",
    "\n",
    "        self.relu = nn.ReLU(True)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "        self.__initialize_weights()\n",
    "\n",
    "    def forward(self, z,label):\n",
    "        input = z.mul_(self.embed(label))\n",
    "        x = input.view(input.size(0), -1, 1, 1)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.conv5(x)\n",
    "        x = self.bn5(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.conv6(x)\n",
    "        output = self.tanh(x)\n",
    "        return output\n",
    "\n",
    "    def __initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                m.weight.data.normal_(0.0, 0.02)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.normal_(1.0, 0.02)\n",
    "                m.bias.data.fill_(0)\n",
    "\n",
    "\n",
    "class D_CIFAR10(nn.Module):\n",
    "\n",
    "    def __init__(self, ndf, nc, num_classes=10):\n",
    "        super(D_CIFAR10, self).__init__()\n",
    "        self.ndf = ndf\n",
    "        self.lrelu = nn.ReLU()\n",
    "        self.conv0 = nn.Conv2d(nc, ndf, 3, 1, 1)\n",
    "        self.bn0 = nn.BatchNorm2d(ndf)\n",
    "        self.conv1 = nn.Conv2d(ndf, ndf, 3, 1, 1)\n",
    "        self.bn1 = nn.BatchNorm2d(ndf)\n",
    "        self.conv2 = nn.Conv2d(ndf, ndf * 2, 4, 2, 1)\n",
    "        self.bn2 = nn.BatchNorm2d(ndf * 2)\n",
    "        self.conv3 = nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1)\n",
    "        self.bn3 = nn.BatchNorm2d(ndf * 4)\n",
    "        self.conv4 = nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1)\n",
    "        self.bn4 = nn.BatchNorm2d(ndf * 8)\n",
    "        self.conv5 = nn.Conv2d(ndf * 8, ndf * 1, 4, 1, 0)\n",
    "        self.gan_linear = nn.Linear(ndf * 1, 1)\n",
    "        self.aux_linear = nn.Linear(ndf * 1, num_classes)\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.__initialize_weights()\n",
    "\n",
    "    def forward(self, input):\n",
    "\n",
    "        x = self.conv0(input)\n",
    "        x = self.bn0(x)\n",
    "        x = self.lrelu(x)\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.lrelu(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.lrelu(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.lrelu(x)\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.lrelu(x)\n",
    "\n",
    "        x = self.conv5(x)\n",
    "        x = x.view(-1, self.ndf * 1)\n",
    "        c = self.aux_linear(x)\n",
    "\n",
    "        s = self.gan_linear(x)\n",
    "        s = self.sigmoid(s)\n",
    "        return s.squeeze(1), c.squeeze(1)\n",
    "\n",
    "    def __initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                m.weight.data.normal_(0.0, 0.02)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.normal_(1.0, 0.02)\n",
    "                m.bias.data.fill_(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'main' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-7d85de46977c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'main' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
